# BiasGuard-The-Bias-in-the-Granting-of-Bank-Loans
# BiasGuard

### Abstract 

This project aims to address bias in loan approval processes, focusing on ethical decision-making in the financial sector. Bias in machine learning models can disproportionately affect minority groups, resulting in unfair treatment. Using the IBM Fairness 360 toolkit, this project examines bias in loan and mortgage data, evaluates fairness, and implements mitigation strategies.  By applying fairness algorithms, the project assesses both pre- and post-processing techniques to minimize bias while ensuring accurate decision-making.


### Problem Statement 

Bias and fairness in bank loan decisions pose a serious issue that impacts people and organizations alike. Usually, historical data—which may represent societal injustices or discriminatory lending practices—is utilized to train AI systems that approve loans. The AI models may reinforce or even magnify unfair treatment if these biases are not adequately recognized and addressed. This is especially true for marginalized groups that are based on characteristics like socioeconomic class, gender, color, or ethnicity.


### The Nature of the Topic

The topic of Ethical AI Monitoring is deeply rooted in the intersection of artificial intelligence (AI), ethics, and regulatory frameworks. It aims to ensure that AI systems operate within ethical boundaries, making decisions that are fair, transparent, and free from harmful bias. The core idea is to audit and monitor AI systems to ensure that they align with ethical standards, particularly in high-impact industries like finance, healthcare, and public services. Ethical AI focuses on building systems that are fair, accountable, and transparent. AI systems can inherit biases from the data they are trained on or the algorithms that power them, which can lead to discrimination, unfair decisions, or lack of transparency. Ethical AI monitoring is the process of detecting and mitigating such issues. The monitoring process identifies biases and helps us to mitigate them. Ethical AI Monitoring represents a growing effort to make AI systems more responsible and to ensure that their increasing role in decision-making processes contributes positively to society rather than reinforcing or amplifying existing inequalities.

### Here is the Poster we made for presenting our work:
<img width="1108" alt="Screenshot 2024-12-06 at 10 06 24 PM" src="https://github.com/user-attachments/assets/7f5d8d7d-b822-42b3-b0e8-2d6a29c6cc43">









The website link to this project is available at: [Link](https://bankloanbias.wordpress.com/)


### Bibliography

https://ffiec.cfpb.gov/

https://www.ibm.com/opensource/open/projects/ai-fairness-360/

https://youtu.be/X1NsrcaRQTE?si=QgkBB2lSODc_eVNE

https://files.consumerfinance.gov/f/documents/cfpb_beginners-guide-accessing-using-hmda-data_guide_2022-06.pdf

https://www.openintro.org/data/index.php?data=loans_full_schema

https://www.kaggle.com/datasets/parisrohan/credit-score-classification?resource=download

